{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OHUcNb15U2vT",
        "WQPM3U9XU2vr"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cerfs21/notebooks/blob/main/4malaria_diagnosis_exercice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_hxzrVpanrY"
      },
      "source": [
        "# Deep Learning for Malaria Diagnosis\n",
        "**Contact:** [Dr. Habiboulaye Amadou-Boubacar](https://www.linkedin.com/in/habiboulaye-amadou-boubacar-8b153710)  \n",
        "This notebook is inspired by works of (Sivaramakrishnan Rajaraman  et al., 2018) and (Jason Brownlee, 2019). Acknowledge to NIH and Bangalor Hospital who make available this malaria dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DyHvXlda9rH"
      },
      "source": [
        "Malaria is an infectuous disease caused by parasites that are transmitted to people through the bites of infected female Anopheles mosquitoes.\n",
        "\n",
        "The Malaria burden with some key figures:\n",
        "<font color='red'>\n",
        "* More than 219 million cases\n",
        "* Over 430 000 deaths in 2017 (Mostly: children & pregnants)\n",
        "* 80% in 15 countries of Africa & India\n",
        "  </font>\n",
        "\n",
        "![MalariaBurd](https://github.com/habiboulaye/ai-labs/blob/master/malaria-diagnosis/doc-images/MalariaBurden.png?raw=1)\n",
        "\n",
        "The malaria diagnosis is performed using blood test:\n",
        "* Collect patient blood smear\n",
        "* Microscopic visualisation of the parasit\n",
        "\n",
        "![MalariaDiag](https://github.com/habiboulaye/ai-labs/blob/master/malaria-diagnosis/doc-images/MalariaDiag.png?raw=1)\n",
        "  \n",
        "Main issues related to traditional diagnosis:\n",
        "<font color='#ed7d31'>\n",
        "* resource-constrained regions\n",
        "* time needed and delays\n",
        "* diagnosis accuracy and cost\n",
        "</font>\n",
        "\n",
        "The objective of this notebook is to apply modern deep learning techniques to perform medical image analysis for malaria diagnosis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5qBTeqkrJ88"
      },
      "source": [
        "*This notebook is inspired by works of (Sivaramakrishnan Rajaraman  et al., 2018), (Adrian Rosebrock, 2018) and (Jason Brownlee, 2019)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K5rb4bmdMRf"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdpDuJOle5sc"
      },
      "source": [
        "* **Useful infos**: *https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxaLbRUnYWTm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "cd07c6f3-10ee-4a42-edf4-abfcdf62e14a"
      },
      "source": [
        "#Mount the local drive project_forder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!ls \"/content/drive/My Drive/Colab Notebooks/10xDS/Projects/malaria-diagnosis/\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-46c754c4d734>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Mount the local drive project_forder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls \"/content/drive/My Drive/Colab Notebooks/10xDS/Projects/malaria-diagnosis/\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    127\u001b[0m   )\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIfORUX7ccHI"
      },
      "source": [
        "# Use GPU: Please check if the outpout is '/device:GPU:0'\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "tf.test.gpu_device_name()\n",
        "#from tensorflow.python.client import device_lib\n",
        "#device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp1o6Cd7dV6Z"
      },
      "source": [
        "## Populating namespaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4Ph8e1uojEC"
      },
      "source": [
        "# Importing basic libraries\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.image import imread\n",
        "%matplotlib inline\n",
        "\n",
        "# Importing the Keras libraries and packages\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Convolution2D as Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOvmLtdRgSIb"
      },
      "source": [
        "# Define the useful paths for data accessibility\n",
        "ai_project = '.' #\"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
        "cell_images_dir = os.path.join(ai_project,'cell_images')\n",
        "training_path = os.path.join(ai_project,'train')\n",
        "testing_path = os.path.join(ai_project,'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11DKlCJcj31w"
      },
      "source": [
        "## Prepare DataSet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "midATIuUq7H7"
      },
      "source": [
        "### *Download* DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCT2ogQdeHPW"
      },
      "source": [
        "# Download the data in the allocated google cloud-server. If already down, turn downloadData=False\n",
        "downloadData = True\n",
        "if downloadData == True:\n",
        "  indrive = False\n",
        "  if indrive == True:\n",
        "    !wget https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip -P \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
        "    !unzip \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis/cell_images.zip\" -d \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis/\"\n",
        "    !ls \"/content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis\"\n",
        "  else: #incloud google server\n",
        "    !rm -rf cell_images.*\n",
        "    !wget https://data.lhncbc.nlm.nih.gov/public/Malaria/cell_images.zip\n",
        "    !unzip cell_images.zip >/dev/null 2>&1\n",
        "    !ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNw0Rvv7U2vK"
      },
      "source": [
        "### Visualize cell images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-18T23:00:47.131389Z",
          "start_time": "2019-07-18T23:00:45.667288Z"
        },
        "id": "E3fVApLxU2vL"
      },
      "source": [
        "# Visualize some samples (randomly selected) of blood smears from healthy patients\n",
        "N_samples = 6\n",
        "uninfected_dir = os.path.join(cell_images_dir,'Uninfected')\n",
        "uninfected_samples = random.sample(os.listdir(uninfected_dir), N_samples)\n",
        "pyplot.figure(figsize=(15,3))\n",
        "print(\"{} Uninfected images: view of {} samples\".format(len(os.listdir(uninfected_dir)), N_samples))\n",
        "i = 0\n",
        "while i < N_samples: # in random.sample(os.listdir(parasitized_dir), 6):\n",
        "    pyplot.subplot(1,N_samples,1+i)\n",
        "    img_uninfected = imread(os.path.join(uninfected_dir, uninfected_samples[i]))\n",
        "    pyplot.imshow(img_uninfected)\n",
        "    i+=1\n",
        "print(img_uninfected.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jdbUxacTVie"
      },
      "source": [
        "<font color='red'>\n",
        "EXERCICE: Similarly, display some samples (randomly selected) of infected blood smears by replacing all <FILL_IN> with the correct codes\n",
        " </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-18T23:00:48.569843Z",
          "start_time": "2019-07-18T23:00:47.135638Z"
        },
        "id": "5bivLkZJU2vQ"
      },
      "source": [
        "# Visualize some samples (randomly selected) of blood smears from patients falciparum-infected\n",
        "print(\"{} Parasitized images: view of {} samples\".format(len(os.listdir(uninfected_dir)), N_samples))\n",
        "parasitized_dir = os.path.join(cell_images_dir,'Parasitized')\n",
        "parasitized_samples = random.sample(os.listdir(parasitized_dir), N_samples)\n",
        "pyplot.figure(figsize=(15,3))\n",
        "i = 0\n",
        "while i < N_samples: # in random.sample(os.listdir(parasitized_dir), 6):\n",
        "    pyplot.subplot(1,N_samples,1+i)\n",
        "    #Not Implemented\n",
        "    <FILL_IN>\n",
        "    <FILL_IN\n",
        "    i+=1\n",
        "print(img_parasitized.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHUcNb15U2vT"
      },
      "source": [
        "### Split train-test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq6VmARGVZLV"
      },
      "source": [
        "def create_train_test_data(class_name, train_split = 0.8):\n",
        "    '''\n",
        "      #Create a function create_train_test_data to split data into\n",
        "      #training and testing sets with respectives proportion 80%, 20%\n",
        "      #--Train (@training_path)\n",
        "          #--Parasitized\n",
        "          #--Uninfected\n",
        "      #--Test (@training_path)\n",
        "          #--Parasitized\n",
        "          #--Uninfected\n",
        "      @class_name: 'Parasitized' or 'Uninfected'\n",
        "      @train_split: eg. 80% train 20% test\n",
        "    '''\n",
        "    train_class_path = os.path.join(training_path,class_name)\n",
        "    test_class_path = os.path.join(testing_path,class_name)\n",
        "\n",
        "    class_img_names = [img for img in os.listdir(os.path.join(cell_images_dir, class_name))]\n",
        "    random.seed(42)\n",
        "    random.shuffle(class_img_names)\n",
        "\n",
        "    # compute the training and testing split\n",
        "    i = int(len(class_img_names) * train_split)\n",
        "    train_class_img_names = class_img_names[:i]\n",
        "    test_class_img_names = class_img_names[i:]\n",
        "\n",
        "    def copy_imgs(learn_class_img_names, learn_class_path):\n",
        "        if not os.path.exists(learn_class_path):\n",
        "            os.makedirs(learn_class_path)\n",
        "        for img in learn_class_img_names:\n",
        "            p_orig = os.path.join(cell_images_dir,class_name,img)\n",
        "            p_dest = os.path.join(learn_class_path,img)\n",
        "            shutil.copy2(p_orig, p_dest)\n",
        "\n",
        "    copy_imgs(train_class_img_names, train_class_path)\n",
        "    copy_imgs(test_class_img_names, test_class_path)\n",
        "\n",
        "SplitTrainTest = True\n",
        "if SplitTrainTest == True:\n",
        "    #Not Implemented\n",
        "    if os.path.exists(training_path): shutil.rmtree(training_path)\n",
        "    if os.path.exists(testing_path): shutil.rmtree(testing_path)\n",
        "    # Create the training and testing subset for Parasitized class by using function create_train_test_data\n",
        "    <FILL IN>\n",
        "    # Create the training and testing subset for Uninfected class by using function create_train_test_data\n",
        "    <FILL IN>\n",
        "!ls train/ test/  # Check if training_path and testing_path folders with both classes are created\n",
        "!ls train/Parasitized | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1LUJGE9U2vW"
      },
      "source": [
        "## Baseline CNN Model\n",
        "Define a basic ConvNet defined with ConvLayer: Conv2D => MaxPooling2D followed by Flatten => Dense => Dense(output)\n",
        "\n",
        "![ConvNet](https://github.com/habiboulaye/ai-labs/blob/master/malaria-diagnosis/doc-images/ConvNet.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T13:20:02.960282Z",
          "start_time": "2019-07-19T13:20:02.952429Z"
        },
        "id": "vFjwvZFuU2vX"
      },
      "source": [
        "#single convolutional layer with 32 filters followed by a max pooling layer.\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "BatchSize = 32\n",
        "xy_shape = 64\n",
        "n_epochs = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XLL56pm273g"
      },
      "source": [
        "<font color='red'>\n",
        "EXERCICE: Replace the <FILL_IN> with the correct codes to complete the 1-layer convolutional neural architecture\n",
        " </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T13:20:03.383789Z",
          "start_time": "2019-07-19T13:20:03.372097Z"
        },
        "id": "n0XSkJNKU2vZ"
      },
      "source": [
        "# define cnn model\n",
        "def simple_cnn_model():\n",
        "    model = Sequential()\n",
        "    # 1 ConvLayer\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(xy_shape, xy_shape, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    # Flatten and Dense layers\n",
        "    model.add(Flatten())\n",
        "    # Add a Dense (Fully Connected) layer with 128 neurons with 'relu' activation with a kernel_initializer='he_uniform'\n",
        "    <FILL_IN>\n",
        "    # Add a Dense output layer with 1 neuron and activated by 'sigmoid'\n",
        "    <FILL_IN>\n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T13:20:07.051451Z",
          "start_time": "2019-07-19T13:20:05.567290Z"
        },
        "id": "oY71FelrU2vb"
      },
      "source": [
        "# Instanciate a data generator to fit the model\n",
        "dataGen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "# prepare iterators\n",
        "train_gen = dataGen.flow_from_directory(training_path,class_mode=\"binary\",target_size=(xy_shape, xy_shape),\n",
        "                                         batch_size=BatchSize)\n",
        "test_gen = dataGen.flow_from_directory(testing_path,class_mode=\"binary\",target_size=(xy_shape, xy_shape),\n",
        "                                        batch_size=BatchSize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-18T23:19:55.478410Z",
          "start_time": "2019-07-18T23:01:12.865662Z"
        },
        "id": "b6ypPV-eU2ve"
      },
      "source": [
        "# Instanciate and train the model\n",
        "conv_net1 = simple_cnn_model()\n",
        "conv_net1_loss_acc_records = conv_net1.fit_generator(train_gen, steps_per_epoch=len(train_gen),validation_data=test_gen, validation_steps=len(test_gen),\n",
        "                              epochs=n_epochs, verbose=1, use_multiprocessing=True)#, workers=) #validation_freq=[1,2,5,10,15,20],"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T13:20:56.619035Z",
          "start_time": "2019-07-19T13:20:56.216075Z"
        },
        "id": "L4ji4dfcU2vl"
      },
      "source": [
        "# This function is defined to visualise loss and accuracy\n",
        "def assess_performance(history):\n",
        "    pyplot.figure(figsize=(15,3))\n",
        "    # plot loss\n",
        "    pyplot.subplot(121)\n",
        "    pyplot.title('Cross Entropy Loss')\n",
        "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    pyplot.subplot(122)\n",
        "    pyplot.title('Classification Accuracy')\n",
        "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\n",
        "assess_performance(conv_net1_loss_acc_records)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T13:21:28.494777Z",
          "start_time": "2019-07-19T13:21:05.270097Z"
        },
        "id": "XCUSdOcEU2vo"
      },
      "source": [
        "# evaluate model\n",
        "_, acc = conv_net1.evaluate_generator(test_gen, steps=len(test_gen), use_multiprocessing=True, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQPM3U9XU2vr"
      },
      "source": [
        "### Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH7nLtfd5z9d"
      },
      "source": [
        "<font color='red'>\n",
        "EXERCICE: Replace the <FILL_IN> with the correct codes to generate new augmented data\n",
        " </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T22:42:23.068905Z",
          "start_time": "2019-07-19T22:42:21.359267Z"
        },
        "id": "WRYA8tt6U2vs"
      },
      "source": [
        "# Use data augmentation techniques to generate more variational data and improve the performance\n",
        "# data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset.\n",
        "# Training deep learning neural network models on more data can result in more skillful models, and the augmentation techniques can create variations of the images that can improve the ability of the fit models to generalize what they have learned to new images.\n",
        "# the training dataset will be augmented with small (10%) random horizontal and vertical shifts and random horizontal flips that create a mirror image of a photo. Photos in both the train and test steps will have their pixel values scaled in the same way.\n",
        "\n",
        "trainAug = ImageDataGenerator(\n",
        "    rescale=1/255.0,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.05,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    shear_range=0.05,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\")\n",
        "# Keep\n",
        "# dataGen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n",
        "# Generate the new training data using augmentation and testing data\n",
        "train_aug = trainAug.flow_from_directory(training_path,class_mode=\"binary\",target_size=(xy_shape, xy_shape),\n",
        "                                         batch_size=BatchSize)\n",
        "test_gen = dataGen.flow_from_directory(testing_path,class_mode=\"binary\",target_size=(xy_shape, xy_shape),\n",
        "                                        batch_size=BatchSize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T13:41:43.953982Z",
          "start_time": "2019-07-19T13:21:30.087007Z"
        },
        "id": "eUHR4_ugU2vv"
      },
      "source": [
        "# Train the model with augmented data and assess the performance\n",
        "conv_net1_aug = simple_cnn_model()\n",
        "conv_net1_aug_loss_acc_records = conv_net1_aug.fit_generator(train_aug, steps_per_epoch=len(train_aug),validation_data=test_gen, validation_steps=len(test_gen),\n",
        "                              epochs=n_epochs, verbose=1, use_multiprocessing=True, workers=2) #validation_freq=[1,2,5,10,15,20],"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T13:41:44.315092Z",
          "start_time": "2019-07-19T13:41:43.959330Z"
        },
        "id": "qTQc03gMU2v0"
      },
      "source": [
        "# Plot loss and accurate and conclude\n",
        "assess_performance(conv_net1_aug_loss_acc_records)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T22:48:43.081318Z",
          "start_time": "2019-07-19T22:48:29.712583Z"
        },
        "id": "5RWjaZd4U2v3"
      },
      "source": [
        "# evaluate model\n",
        "_, acc = conv_net1_aug.evaluate_generator(test_gen, steps=len(test_gen), use_multiprocessing=True, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfOHmLLqU2v_"
      },
      "source": [
        "## 2-ConvLayers CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TsPIVqSU2wA"
      },
      "source": [
        "<font color='red'>\n",
        "EXERCICE: Create a CNN with 2 ConvLayers by replacing all the <FILL_IN> with the correct codes\n",
        " </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T02:36:08.395886Z",
          "start_time": "2019-07-19T02:36:08.388250Z"
        },
        "id": "TxJKHRXYU2wA"
      },
      "source": [
        "def cnn_model():\n",
        "    '''\n",
        "      Create the 2 layers ConvNet: FirstConvLayer > FirstConvLayer > Flatten > Dense > Dense(output)\n",
        "    '''\n",
        "    # Not Implemmented\n",
        "    model = Sequential()\n",
        "    # First ConvLayer: use-ing 32 3x3-filters, 'relu' activation function, kernel_initializer='he_uniform', padding='same' with the correct input shape\n",
        "    <FILL_IN> #Conv2D with above listed parameters\n",
        "    <FILL_IN> #MaxPooling2D with shape 2x2\n",
        "    # Second ConvLayer: use-ing 32 3x3-filters, 'relu' activation function\n",
        "    <FILL_IN> #Conv2D with above listed parameters\n",
        "    <FILL_IN> #MaxPooling2D with shape 2x2\n",
        "    # Flatten followed by Dense and sigmoid Ouput Layers\n",
        "    <FILL_IN> # Flatten\n",
        "    <FILL_IN> # Dense with 128 neurones, activation='relu', kernel_initializer='he_uniform'\n",
        "    <FILL_IN> # Dense with 1 neuron activate by 'sigmoid' function\n",
        "    # compile model\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T13:16:33.370752Z",
          "start_time": "2019-07-19T13:16:28.904006Z"
        },
        "id": "-M10PDxEU2wC"
      },
      "source": [
        "conv_net2_aug = cnn_model()\n",
        "conv_net2_aug_loss_acc_records = conv_net2_aug.fit_generator(train_aug, steps_per_epoch=len(train_aug),validation_data=test_gen, validation_steps=len(test_gen),\n",
        "                              epochs=n_epochs, verbose=1, use_multiprocessing=True, workers=2) #validation_freq=[1,2,5,10,15,20],"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T03:33:57.521889Z",
          "start_time": "2019-07-19T03:33:57.210208Z"
        },
        "id": "1ycAVGY7U2wF"
      },
      "source": [
        "assess_performance(conv_net2_aug_loss_acc_records)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T22:46:18.246335Z",
          "start_time": "2019-07-19T22:46:18.061802Z"
        },
        "id": "sizAC7n_U2wI"
      },
      "source": [
        "# evaluate model\n",
        "_, acc = conv_net2_aug.evaluate_generator(test_gen, steps=len(test_gen), use_multiprocessing=True, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAbkGNr6U2we"
      },
      "source": [
        "## Prediction: Automatic AI-based malaria diagnosis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T22:34:40.858310Z",
          "start_time": "2019-07-19T22:34:40.844058Z"
        },
        "id": "HlEHLtHgU2we"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "# load and prepare the image\n",
        "def load_image(filename, xy_shape=xy_shape):\n",
        "    # load the image\n",
        "    img = load_img(filename, target_size=(xy_shape, xy_shape))\n",
        "    pyplot.imshow(img)\n",
        "    # convert to array\n",
        "    img = img_to_array(img)\n",
        "    #print(img)\n",
        "    # reshape into a single sample with 3 channels\n",
        "    img = img.reshape(1, xy_shape, xy_shape, 3)\n",
        "    # center pixel data\n",
        "    img = img.astype('float32')/255\n",
        "    #img = img - [123.68, 116.779, 103.939]\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEeOo-uzQfcL"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T22:34:42.103134Z",
          "start_time": "2019-07-19T22:34:41.891976Z"
        },
        "id": "hY6MZKRPU2wh"
      },
      "source": [
        "#!cp /content/drive/My Drive/Colab Notebooks/ai-labs/malaria-diagnosis/physician_questions/patient_1.png .\n",
        "!wget https://github.com/habiboulaye/ai-labs/blob/master/malaria-diagnosis/physician_questions/patient_1.png\n",
        "p_ask_image = 'patient_1.png' #os.path.join('physician_questions', 'patient_4.png')\n",
        "image = load_image(p_ask_image)\n",
        "pred_prod = conv_net2_aug.predict(image)[0][0]\n",
        "print('Prediction: {:.2%} => {}'.format(pred_prod, 'Uninfected' if pred_prod > 0.5 else 'Parasitized'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh9mjlH0U2wM"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T15:57:37.509728Z",
          "start_time": "2019-07-19T15:57:37.497541Z"
        },
        "id": "8NrvHr5mU2wN"
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "# define cnn model\n",
        "xy_shape3 = 224\n",
        "BatchSize3 = 64\n",
        "def deep_cnn_transfer_model():\n",
        "    model = VGG16(include_top=False, input_shape=(xy_shape3, xy_shape3, 3))\n",
        "    # mark loaded layers as not trainable\n",
        "    nb_layers = len(model.layers)\n",
        "    print('nb_layers:',nb_layers)\n",
        "    for layer in model.layers: #[:nb_layers-5]:  #model.layers[1:20]\n",
        "        layer.trainable=False\n",
        "    # add new classifier layers\n",
        "    flat1 = Flatten()(model.layers[-1].output)\n",
        "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "    output = Dense(1, activation='sigmoid')(class1)\n",
        "    # define new model\n",
        "    model = Model(inputs=model.inputs, outputs=output)\n",
        "    # compile model\n",
        "    #opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T15:57:42.006586Z",
          "start_time": "2019-07-19T15:57:39.835559Z"
        },
        "id": "H8C3MiC8U2wP"
      },
      "source": [
        "conv_deep_transfer = deep_cnn_transfer_model()\n",
        "conv_deep_transfer.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T15:58:02.509561Z",
          "start_time": "2019-07-19T15:57:59.195012Z"
        },
        "id": "Agl12RKpU2wS"
      },
      "source": [
        "train_aug = trainAug.flow_from_directory(training_path,class_mode=\"binary\",target_size=(xy_shape3, xy_shape3),\n",
        "                                         batch_size=BatchSize3)\n",
        "test_gen = dataGen.flow_from_directory(testing_path,class_mode=\"binary\",target_size=(xy_shape3, xy_shape3),\n",
        "                                        batch_size=BatchSize3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T16:52:19.371943Z",
          "start_time": "2019-07-19T16:28:04.898140Z"
        },
        "id": "SQMItypbU2wU"
      },
      "source": [
        "conv_deep_transfer_loss_acc_records = conv_deep_transfer.fit_generator(train_aug, steps_per_epoch=len(train_aug),validation_data=test_gen, validation_steps=len(test_gen),\n",
        "                              epochs=n_epochs, verbose=1, use_multiprocessing=True, workers=2) #validation_freq=[1,2,5,10,15,20],"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T03:34:24.229615Z",
          "start_time": "2019-07-19T02:50:37.914Z"
        },
        "id": "RAS2g2L-U2wX"
      },
      "source": [
        "assess_performance(conv_deep_transfer_loss_acc_records)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-07-19T03:34:24.230966Z",
          "start_time": "2019-07-19T02:50:42.457Z"
        },
        "id": "5ZdS8CueU2wZ"
      },
      "source": [
        "# evaluate model\n",
        "_, acc = conv_deep_transfer.evaluate_generator(test_gen, steps=len(test_gen), use_multiprocessing=True, verbose=0)\n",
        "print('> %.3f' % (acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzaxZJrMiVro"
      },
      "source": [
        "## Compare performance results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjoFu02jil4V"
      },
      "source": [
        "*   conv_net1:\n",
        "*   conv_net1_aug\n",
        "*   conv_net2_aug:\n",
        "*   conv_deep_transfer:\n",
        "\n",
        "***Conclusion:***"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment: Work to improve the performance - try different strategies:\n",
        "* Hyperparameters tuning\n",
        "* Test other models\n",
        "  - eg. ResNet, VGG"
      ],
      "metadata": {
        "id": "pjnHwwTcTKhH"
      }
    }
  ]
}